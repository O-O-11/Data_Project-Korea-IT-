{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# A. 데이터 로드 및 이진 타겟 변수 생성\n",
        "# 파일 경로를 \"test1_all.csv\"로 수정합니다.\n",
        "file_path = \"test1_all.csv\"\n",
        "test1_all = pd.read_csv(file_path)\n"
      ],
      "metadata": {
        "id": "G9dDhH8CwB3F"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 1. 타겟 변수 이진화: PHQ_score를 10점 기준으로 변환\n",
        "y_binary = (test1_all[\"PHQ_score\"] >= 10).astype(int)\n",
        "\n",
        "# 2. 독립 변수 X 설정 (PHQ_score는 종속 변수이므로 제거)\n",
        "X = test1_all.drop(\"PHQ_score\", axis = 1)\n",
        "\n",
        "# 3. 데이터 분할 및 계층화 (Stratified Split)\n",
        "# 이진 분류는 클래스 불균형이 중요하므로, 반드시 y_binary를 기준으로 계층화해야 합니다.\n",
        "X_train, X_valid, y_train_binary, y_valid_binary = train_test_split(\n",
        "    X,\n",
        "    y_binary,\n",
        "    train_size = 0.75,\n",
        "    random_state=2025,\n",
        "    stratify = y_binary\n",
        ")\n",
        "\n",
        "# 4. 특성 스케일링\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "\n",
        "print(\"3번 모델 데이터 준비 완료!\")\n",
        "print(f\"훈련 세트 크기: X_train: {X_train.shape}, y_train_binary: {y_train_binary.shape}\")\n",
        "print(f\"검증 세트 크기: X_valid: {X_valid.shape}, y_valid_binary: {y_valid_binary.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFDluB65wglg",
        "outputId": "e1fa2979-2f2e-4faa-de39-d36fb8cb5b32"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3번 모델 데이터 준비 완료!\n",
            "훈련 세트 크기: X_train: (23003, 88), y_train_binary: (23003,)\n",
            "검증 세트 크기: X_valid: (7668, 88), y_valid_binary: (7668,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "# 훈련 세트(X_train)에 fit_transform을 적용하여 평균과 표준편차를 학습합니다.\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 검증 세트(X_valid)에는 훈련 세트에서 학습한 scaler를 사용하여 transform만 적용합니다.\n",
        "X_valid_scaled = scaler.transform(X_valid)"
      ],
      "metadata": {
        "id": "Xx1-dgmzzWt0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# ***********************************************\n",
        "# ⭐ 1. 파일 경로 수정 (실제 파일 경로로 변경) ⭐\n",
        "file_path = \"test1_all.csv\"\n",
        "test1_all = pd.read_csv(file_path)\n",
        "# ***********************************************\n",
        "\n",
        "# 2. 타겟 변수 이진화 (PHQ score >= 10)\n",
        "test1_all['is_depressed'] = (test1_all['PHQ_score'] >= 10).astype(int)\n",
        "y_binary = test1_all['is_depressed']\n",
        "\n",
        "# 3. ⭐ 타겟 누수 해결: PHQ 개별 문항과 총점을 모두 제거한 X_clean 정의 ⭐\n",
        "phq_items_to_drop = [col for col in test1_all.columns if col.startswith('BP_PHQ_')]\n",
        "columns_to_drop = ['PHQ_score', 'is_depressed'] + phq_items_to_drop\n",
        "\n",
        "X_clean = test1_all.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# 4. 데이터 분할 (X_clean 사용)\n",
        "X_train_clean, X_valid_clean, y_train_binary, y_valid_binary = train_test_split(\n",
        "    X_clean,\n",
        "    y_binary,\n",
        "    train_size=0.75,\n",
        "    random_state=2025,\n",
        "    stratify=y_binary\n",
        ")\n",
        "\n",
        "# 5. 특성 스케일링\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_clean = scaler.fit_transform(X_train_clean)\n",
        "X_valid_scaled_clean = scaler.transform(X_valid_clean)\n",
        "\n",
        "# 6. 모델 객체 생성 및 학습\n",
        "xgb_model_cls = XGBClassifier(\n",
        "    max_depth=4,\n",
        "    learning_rate=0.05,\n",
        "    n_estimators=500,\n",
        "    objective='binary:logistic', # 이진 분류\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "# ⭐ 학습 ⭐\n",
        "xgb_model_cls.fit(X_train_scaled_clean, y_train_binary)\n",
        "\n",
        "# 7. 예측 및 평가\n",
        "pred_xgb_cls = xgb_model_cls.predict(X_valid_scaled_clean)\n",
        "pred_proba_xgb_cls = xgb_model_cls.predict_proba(X_valid_scaled_clean)[:, 1]\n",
        "\n",
        "accuracy = accuracy_score(y_valid_binary, pred_xgb_cls)\n",
        "roc_auc = roc_auc_score(y_valid_binary, pred_proba_xgb_cls)\n",
        "f1 = f1_score(y_valid_binary, pred_xgb_cls)\n",
        "\n",
        "print(\"\\n=== 모델 3번 (이진 분류) - XGBoost Classifier 최종 결과 ===\")\n",
        "print(f\"XGBoost Accuracy: {accuracy:.4f}\")\n",
        "print(f\"XGBoost ROC AUC: {roc_auc:.4f}\")\n",
        "print(f\"XGBoost F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwNuoSFL09KD",
        "outputId": "5c7e7ea9-d285-4281-ebdc-8f42ae60ff05"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 모델 3번 (이진 분류) - XGBoost Classifier 최종 결과 ===\n",
            "XGBoost Accuracy: 0.7838\n",
            "XGBoost ROC AUC: 0.8333\n",
            "XGBoost F1-Score: 0.5872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"### 1. Random Forest Classifier (변수 중요도 해석)\")\n",
        "\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=400, max_depth=12, min_samples_split=4,\n",
        "    min_samples_leaf=2, random_state=42\n",
        ")\n",
        "rf_model.fit(X_train_scaled_clean, y_train_binary)\n",
        "\n",
        "y_pred_rf = rf_model.predict(X_valid_scaled_clean)\n",
        "y_proba_rf = rf_model.predict_proba(X_valid_scaled_clean)[:, 1]\n",
        "\n",
        "# 성능 계산\n",
        "f1_rf = f1_score(y_valid_binary, y_pred_rf)\n",
        "roc_auc_rf = roc_auc_score(y_valid_binary, y_proba_rf)\n",
        "\n",
        "print(f\"F1-Score: {f1_rf:.4f}, ROC AUC: {roc_auc_rf:.4f}\")\n",
        "\n",
        "# ⭐ 변수 중요도 해석 ⭐\n",
        "importances_rf = pd.Series(rf_model.feature_importances_, index=X_train_clean.columns)\n",
        "top_importances_rf = importances_rf.sort_values(ascending=False).head(10)\n",
        "print(\"\\n[변수 중요도 해석 (Top 10):]\")\n",
        "print(top_importances_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTU3KcIa1A6p",
        "outputId": "1da73e78-3970-488a-f53d-56dea1d7f67b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "### 1. Random Forest Classifier (변수 중요도 해석)\n",
            "F1-Score: 0.5491, ROC AUC: 0.8311\n",
            "\n",
            "[변수 중요도 해석 (Top 10):]\n",
            "BP1          0.137890\n",
            "LQ_5EQL      0.105301\n",
            "D_1_1        0.071996\n",
            "age          0.035757\n",
            "LQ_4EQL      0.027107\n",
            "D_2_wk       0.024533\n",
            "EC_lgw_2     0.024439\n",
            "EC_wht_23    0.023781\n",
            "BE3_walk     0.022785\n",
            "BE8_sit      0.021153\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"### 2. Logistic Regression (가중치 해석)\")\n",
        "\n",
        "log_model = LogisticRegression(solver='liblinear', random_state=2025)\n",
        "log_model.fit(X_train_scaled_clean, y_train_binary)\n",
        "\n",
        "y_pred_log = log_model.predict(X_valid_scaled_clean)\n",
        "y_proba_log = log_model.predict_proba(X_valid_scaled_clean)[:, 1]\n",
        "\n",
        "# 성능 계산\n",
        "f1_log = f1_score(y_valid_binary, y_pred_log)\n",
        "roc_auc_log = roc_auc_score(y_valid_binary, y_proba_log)\n",
        "\n",
        "print(f\"F1-Score: {f1_log:.4f}, ROC AUC: {roc_auc_log:.4f}\")\n",
        "\n",
        "# ⭐ 가중치(계수) 해석 ⭐\n",
        "coef_log = pd.Series(log_model.coef_[0], index=X_train_clean.columns)\n",
        "top_coefs_log = coef_log.sort_values(ascending=False).head(10)\n",
        "print(\"\\n[가중치 해석 (Top 10):]\")\n",
        "print(top_coefs_log)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybEUktYd3IRZ",
        "outputId": "9821c0ba-1656-4bcb-b8f9-61b94d592bd5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "### 2. Logistic Regression (가중치 해석)\n",
            "F1-Score: 0.5795, ROC AUC: 0.8296\n",
            "\n",
            "[가중치 해석 (Top 10):]\n",
            "EC1_1      2.294520\n",
            "BP6_31     1.610372\n",
            "marri_2    1.217672\n",
            "LQ4_15     0.887048\n",
            "LQ_5EQL    0.426256\n",
            "BD1        0.408117\n",
            "D_1_1      0.369989\n",
            "sex        0.323520\n",
            "BD7_4      0.267351\n",
            "occp       0.160553\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "# FrozenEstimator는 코드를 실행하는 환경에 따라 Import 위치가 달라질 수 있습니다.\n",
        "# from sklearn.utils._testing import FrozenEstimator\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"### 3. Support Vector Machine (선형 SVM) - 최종 코드\")\n",
        "\n",
        "# LinearSVC 모델 학습\n",
        "svm_model = LinearSVC(C=1.0, random_state=2025, dual=False)\n",
        "svm_model.fit(X_train_scaled_clean, y_train_binary)\n",
        "\n",
        "# F1-Score는 직접 예측으로 계산\n",
        "y_pred_svm = svm_model.predict(X_valid_scaled_clean)\n",
        "\n",
        "# ROC AUC 계산을 위해 확률 값 보정 (FrozenEstimator를 사용하여 경고를 무시하고 진행)\n",
        "calibrated_svm = CalibratedClassifierCV(svm_model, method='sigmoid', cv=3)\n",
        "calibrated_svm.fit(X_valid_scaled_clean, y_valid_binary)\n",
        "y_proba_svm = calibrated_svm.predict_proba(X_valid_scaled_clean)[:, 1]\n",
        "\n",
        "# 성능 계산\n",
        "f1_svm = f1_score(y_valid_binary, y_pred_svm)\n",
        "roc_auc_svm = roc_auc_score(y_valid_binary, y_proba_svm)\n",
        "\n",
        "print(f\"F1-Score: {f1_svm:.4f}, ROC AUC: {roc_auc_svm:.4f}\")\n",
        "\n",
        "# 가중치(계수) 해석\n",
        "coef_svm = pd.Series(svm_model.coef_[0], index=X_train_clean.columns)\n",
        "top_coefs_svm = coef_svm.sort_values(ascending=False).head(10)\n",
        "print(\"\\n[가중치 해석 (Top 10):]\")\n",
        "print(top_coefs_svm)\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_MLOn9c3MZU",
        "outputId": "96d40b15-f198-4a93-dc72-531f858f12e0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "### 3. Support Vector Machine (선형 SVM) - 최종 코드\n",
            "F1-Score: 0.5626, ROC AUC: 0.8360\n",
            "\n",
            "[가중치 해석 (Top 10):]\n",
            "marri_2    0.862897\n",
            "BP6_31     0.776865\n",
            "EC1_1      0.686932\n",
            "LQ4_15     0.365848\n",
            "LQ_5EQL    0.169465\n",
            "BD1        0.151566\n",
            "D_1_1      0.130871\n",
            "sex        0.114646\n",
            "BD7_4      0.096335\n",
            "LQ2_ab     0.046176\n",
            "dtype: float64\n",
            "==================================================\n"
          ]
        }
      ]
    }
  ]
}